# -*- coding: utf-8 -*-
"""BostonRegression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tPchQY33JkaWM9f01HKtIjRdzD1wNpbE
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.model_selection import train_test_split

from sklearn.datasets import load_boston
data, target = load_boston(return_X_y=True)
features = load_boston()['feature_names']
data = pd.DataFrame(data, columns=features)
data['PRICE'] = target
data

data.corr()

sns.pairplot(data)

"""**Useful features:**


1.   LSTAT
2.   RM
3.   DIS
4.   INDUS
"""

fig, axs = plt.subplots(nrows=2, ncols=7, figsize=(16,4))
plt.tight_layout()

cols = data.columns
index = 0
for i in range(2):
  for j in range(7):
    axs[i][j].hist(data[cols[index]])
    axs[i][j].set_xlabel(cols[index])
    index += 1

"""USEFUL FEATURES:


1.   DIS
2.   AGE
3.   RM(IMPORTANT FEATURE)
4.   LSTAT
5.   NOX
6.   PTRATIO
"""

fig, axs = plt.subplots(figsize=(18,10))
sns.heatmap(data.corr(), annot=True, annot_kws={'size':12})

"""**Features with corr > .5**


1.   LSTAT
2.   PTRATIO
3.   RM
"""

selectedFeatures = data[['LSTAT', 'PTRATIO', 'RM']]

#Split the data
X_train, X_test, y_train, y_test = train_test_split(selectedFeatures, target, test_size=0.4, shuffle=False)
X_train.head()

#LinearModelSection
#Train the model using multiple features
linModel = LinearRegression()
linModel.fit(X_train, y_train)

#Predict Data(Training Data)
predictedTrainVals = linModel.predict(X_train)

for i in range(len(selectedFeatures.columns)):
  plt.scatter(X_train[selectedFeatures.columns[i]], y_train, color='red')
  plt.scatter(X_train[selectedFeatures.columns[i]], predictedTrainVals, color='green')
  plt.show()

#Measuring Accuracy
error = mean_squared_error(y_train, predictedTrainVals)
error

#Predicting Testing Data and calculating mse
predictedTestVals = linModel.predict(X_test)
error = mean_squared_error(predictedTestVals, y_test)
error
for i in range(len(selectedFeatures.columns)):
  plt.title(selectedFeatures.columns[i] + " vs " + "Price")
  plt.scatter(X_test[selectedFeatures.columns[i]], y_test, color='red', label='Original Data')
  plt.scatter(X_test[selectedFeatures.columns[i]], predictedTestVals, color='green', label="Predicted Data")
  #plt.plot(X_test[selectedFeatures.columns[i]], predictedTestVals, color='aqua')
  plt.legend()
  plt.show()

#Using single independent variable of highest correlation
#Training model
linModel1 = LinearRegression()
x = X_train['RM'].values.reshape(-1,1)
y = y_train
linModel1.fit(x, y)

predictedTrainVals1 = linModel1.predict(x)
error = mean_squared_error(predictedTrainVals1, y_train)
error

#Plotting the single variate data
plt.scatter(x, y, color='red')
plt.scatter(x, predictedTrainVals1, color='green')
plt.plot(x, predictedTrainVals1, color='aqua')

#Although the data seems linear and im sure decision tree is not for this
#But still trying
#So, training a decision tree model
decisionModel = DecisionTreeRegressor(max_depth=3)
decisionModel.fit(X_train, y_train)

predictedTreeValues = decisionModel.predict(X_train)
plt.scatter(X_train["RM"], y_train, color='red')
plt.scatter(X_train['RM'], predictedTreeValues, color='green')
plt.show()

#Calculate error for this model
errorTreeTrain = mean_squared_error(predictedTreeValues, y_train)
errorTreeTrain
#This seems the lowest but im afraid it's overfitted data
#So lets check it in test values
errorTreeTest = mean_squared_error(decisionModel.predict(X_test), y_test)
errorTreeTrain, errorTreeTest
#This is wrong, and i knew it

#I think this tree model could do better if I used all features
#So training another tree model
treeModel2 = DecisionTreeRegressor(max_depth=4)
data.drop(['PRICE'], axis=1)

#Lets split data to figureout over or underfitting later
X_train1, X_test1, y_train1, y_test1 = train_test_split(data, target, test_size=0.4, shuffle=False)

treeModel2.fit(X_train1, y_train1)

predictedTreeVals2 = treeModel2.predict(X_train1)
errorTree2 = mean_squared_error(predictedTreeVals2, y_train)
errorTree2
#Hmm error is certainly lower, lets plot curves before testing with test data

predictedTreeValsTest2 = treeModel2.predict(X_test1)
errorTreeTest2 = mean_squared_error(predictedTreeValsTest2, y_test)
errorTreeTest2, errorTree2
#Hmm, it certainly is better version, but I think bagging with decision tree can help us out here since variation is high between training and testing predictions
#Let's try that out

from sklearn.ensemble import BaggingRegressor

baggingModel = BaggingRegressor(base_estimator=DecisionTreeRegressor(), n_estimators = 20)
baggingModel.fit(X_train, y_train)

errorBagging = mean_squared_error(y_train, baggingModel.predict(X_train))
errorBagging

#Testing data
errorBaggingTest = mean_squared_error(y_test, baggingModel.predict(X_test))
errorBaggingTest, errorBagging

#Lets try boostong the model
from sklearn.ensemble import AdaBoostRegressor
boostingModel = AdaBoostRegressor(learning_rate=0.01, n_estimators=10)
boostingModel.fit(X_train, y_train)

trainingBoostError = mean_squared_error(y_train, boostingModel.predict(X_train))
testingBoostError = mean_squared_error(y_test, boostingModel.predict(X_test))
trainingBoostError, testingBoostError

"""By far, my decision tree regressor with depth 4 turned out to be the highly accurate model, relatively speaking. So, treeModel2 is the model to use in this analysis. But the bad thing is, I have to provide multiple features during prediction as well. One value cannot predict the accurately, unless we use older linear models."""