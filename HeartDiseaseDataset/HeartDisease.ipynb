{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aHMZQVeENZDA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHGmDoDmQnIi"
   },
   "outputs": [],
   "source": [
    "#Importing data refining modules\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importing Classifying Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn import svm\n",
    "#Performance measuring modules\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "yEPDKrLRRB-1",
    "outputId": "9dd6e988-05fd-4cfc-ceca-fdcc040a7540"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('heart.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "uWLdgi5aRbsI",
    "outputId": "793491b8-bed5-44bd-89dc-23a89684c5e9"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 317
    },
    "id": "HpGl55KpeLX1",
    "outputId": "7a2ca034-269d-40e3-e918-fed3c530bdd2"
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3IzkeOWRiaW"
   },
   "source": [
    "No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "jyVWF9ktRkwP",
    "outputId": "96eda9ae-898d-4f95-8237-2f82b2c296e7"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='target' ,data=data)\n",
    "plt.xticks([0,1], ['No Heart Disease', 'Heart Disease'])\n",
    "plt.title('Heart Disease Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gzVBF15TSGDH"
   },
   "source": [
    "Almost balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "id": "HMnDhBOLSH5m",
    "outputId": "81da51cc-110f-4c30-cfa7-ef22b6d1ccdc"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='sex', data = data, hue='target')\n",
    "plt.xticks([0,1], ['Female', 'Male'])\n",
    "plt.title('Heart Disease Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2JvNhjNY_0X"
   },
   "source": [
    "Mens are likely to have heart disease slightly more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "oA_M-7j2SeNd",
    "outputId": "6ba83909-80ea-43d5-b368-6898bc8216db"
   },
   "outputs": [],
   "source": [
    "pd.crosstab(data.age, data.target).plot(kind='bar', figsize=(20,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hNmrTmHPZIxz"
   },
   "source": [
    "There are significantly more people with heart disease from age 37 to 54 than in other age group.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "ErKfryKiZeNS",
    "outputId": "986594ef-34c5-474e-a152-4a795d313f49"
   },
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(figsize=(20,8))\n",
    "sns.heatmap(data=data.corr(), annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRnypHM-aDGf"
   },
   "source": [
    "# Features with Correlation > 0.3 with target\n",
    "\n",
    "\n",
    "1.   Thal\n",
    "2.   CA\n",
    "3.   slope\n",
    "4.   oldpeak\n",
    "5.   exang\n",
    "6.   thalach\n",
    "7.   cp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "UmEBDB2FZ3-K",
    "outputId": "197c33eb-d780-4a3d-ed39-8e2047ea95ef"
   },
   "outputs": [],
   "source": [
    "data.corr().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Yx_q-t0amRd"
   },
   "source": [
    "##Making a feature filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "id": "s1uiaMT4arqt",
    "outputId": "5c44f4b9-db7f-4c65-8894-69d91a73faea"
   },
   "outputs": [],
   "source": [
    "#Returns filtered dataframe with features having correlation with target > threshold value\n",
    "corr_threshold = 0.2\n",
    "def featureFilter(data = None, corr_threshold = 0.3):\n",
    "  selected_features = []\n",
    "  for i in range(len(data.columns)-1):\n",
    "    if abs(data[data.columns[i]].corr(data['target'])) > corr_threshold:\n",
    "      selected_features.append(data.columns[i])\n",
    "  new_data = pd.DataFrame()\n",
    "  for i in selected_features:\n",
    "    new_data[i] = data[i]\n",
    "  return new_data\n",
    "\n",
    "new_data = featureFilter(data, corr_threshold = corr_threshold)\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "Ol8rPe5KbPks",
    "outputId": "91728bb2-54f1-4833-c606-91c09efbef7d"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='age', y='sex', data=data, hue='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5LbqMi_oo1Fq"
   },
   "source": [
    "Now Encoding the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "xo0rhYb-kA15",
    "outputId": "b8d71bae-fafd-422c-eba6-b1f3747edffe"
   },
   "outputs": [],
   "source": [
    "x = new_data.iloc[:, :].values\n",
    "y = data['target'].values\n",
    "\n",
    "#convert_to_categorical = ColumnTransformer([('encoder', OneHotEncoder(), [i for i in range(7)])], remainder = 'passthrough')\n",
    "#x_converted = convert_to_categorical.fit_transform(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "XFHZFAAesvOf",
    "outputId": "b148e5fd-1988-42f3-c04d-2d15c0f9a321"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhp9Cc-apD7f"
   },
   "source": [
    "Now Scaling the features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxwLfGpvh77x"
   },
   "source": [
    "##Trying Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "Z2Cy9jymh58h",
    "outputId": "5bb772cf-7995-4434-f352-0f64f3f8ebac"
   },
   "outputs": [],
   "source": [
    "#Training Model\n",
    "lModel = LogisticRegression(max_iter=500)\n",
    "lModel.fit(X_train, y_train)\n",
    "\n",
    "#Predicting\n",
    "predictedVals = lModel.predict(X_train)\n",
    "\n",
    "\n",
    "#Testing with test data\n",
    "predictedTestVals = lModel.predict(X_test)\n",
    "\n",
    "print(\"Training Data's Confusion Matrix:\\n\", confusion_matrix(y_train, predictedVals))\n",
    "print(\"Testing Data\\'s Confusion Matrix:\\n\", confusion_matrix(y_test, predictedTestVals))\n",
    "print('\\nTraining Data\\'s Accuracy Score: ', accuracy_score(y_train, predictedVals))\n",
    "print('Testing Data\\'s Accuracy Score: ', accuracy_score(y_test, predictedTestVals))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLDBiqp8ydnJ"
   },
   "source": [
    "Hmm, pretty good result we've got here but it's overfitted. Let's try other models as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IId3ZzqXznL6"
   },
   "source": [
    "##Trying KNN Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "T_6rioLczqDC",
    "outputId": "634cf0b7-32e2-432a-d72d-49a13aff41ba"
   },
   "outputs": [],
   "source": [
    "new_data = featureFilter(data, corr_threshold=0.3)\n",
    "\n",
    "x=new_data.iloc[:,:]\n",
    "y=data['target']\n",
    "\n",
    "#Lets Scale data\n",
    "scalar = StandardScaler()\n",
    "x = scalar.fit_transform(x)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "DSZlAHNI1jYl",
    "outputId": "2dfd0597-c43f-47b7-9cd8-390a9ef7a91c"
   },
   "outputs": [],
   "source": [
    "#Train\n",
    "kClassifier = KNeighborsClassifier(n_neighbors = 20)\n",
    "kClassifier.fit(X_train, y_train)\n",
    "\n",
    "predictedVals = kClassifier.predict(X_train)\n",
    "predictedTestVals = kClassifier.predict(X_test)\n",
    "\n",
    "print(\"Training Data's Confusion Matrix:\\n\", confusion_matrix(y_train, predictedVals))\n",
    "print(\"Testing Data\\'s Confusion Matrix:\\n\", confusion_matrix(y_test, predictedTestVals))\n",
    "\n",
    "print('\\nTraining Data\\'s Accuracy Score: ', accuracy_score(y_train, predictedVals))\n",
    "print('Testing Data\\'s Accuracy Score: ', accuracy_score(y_test, predictedTestVals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgzLJS194R3J"
   },
   "source": [
    "Hmm, better than LogisticRegression. Cool, it's performed with test data better than training data. But it could be due to luck while splitting the train-test data.\n",
    "Now, let's try Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcj9ybiD4cWL"
   },
   "source": [
    "##Trying Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "9FLkRnRN4bee",
    "outputId": "ba0257d5-e495-4d6e-fc2f-22514a04dfb7"
   },
   "outputs": [],
   "source": [
    "new_data = featureFilter(data, corr_threshold=0.3)\n",
    "\n",
    "x = new_data.iloc[:,:]\n",
    "y = data['target']\n",
    "\n",
    "x = scalar.fit_transform(x)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "drhlrrSX5Jqz",
    "outputId": "f13982a0-add6-44b9-9f40-61010729eae7"
   },
   "outputs": [],
   "source": [
    "def parametersTuner(split = 2, leaf = 1, diff_threshold = 0.2):\n",
    "  '''\n",
    "    Params:\n",
    "      split: (integer) \n",
    "      leaf: (integer)\n",
    "    Returns: The best decision tree with optimal value of two parameters: min_sample_leaf and min_sample_split\n",
    "  '''\n",
    "  performanceRecord = {}    #ClassifierObject : (trainScore, testScore)\n",
    "  for splitVar in range(2, split):\n",
    "    for leafVar in range(1, leaf):\n",
    "\n",
    "      #First instantiate a classifier object\n",
    "      treeClassifier = DecisionTreeClassifier(min_samples_split=splitVar, min_samples_leaf = leafVar)\n",
    "\n",
    "      #Then Train the classifier with the specified test parameters\n",
    "      treeClassifier.fit(X_train, y_train)\n",
    "\n",
    "      #Predict\n",
    "      predictedVals = treeClassifier.predict(X_train)\n",
    "      predictedTestVals = treeClassifier.predict(X_test)\n",
    "\n",
    "      #Measure Accuracy\n",
    "      trainScore = accuracy_score(y_train, predictedVals)\n",
    "      testScore = accuracy_score(y_test, predictedTestVals)\n",
    "\n",
    "      #Store the classifier and it's performance in dict object if the variance is inside acceptable range\n",
    "      if abs(trainScore-testScore) <= diff_threshold and trainScore > 0.5 and testScore > 0.5:\n",
    "        performanceRecord[treeClassifier] = (trainScore, testScore)\n",
    "\n",
    "  #Sort the preformanceRecord in decending order with respect to testing accuracy\n",
    "  performanceRecord = {k:v for k,v in sorted(performanceRecord.items(), key = lambda item: item[1])}\n",
    "\n",
    "  #for k,v in performanceRecord.items():\n",
    "   # print('\\nClassifier: ', \"\\nAccuracy: \", v[1], \"\\nDifference: \", abs(v[0]-v[1]))                     \n",
    "  #Compare performance of each classifier stored\n",
    "  #Rules of optimal tree:\n",
    "    #-> Least distance between test and train data prediction\n",
    "    #-> Highest Accuracy\n",
    "  optimalModel = {DecisionTreeClassifier() : (math.inf, 0)}     #ClassifierObject : (trainScore, testScore)\n",
    "  for key, val in performanceRecord.items():\n",
    "      if abs(val[0]-val[1]) < abs(optimalModel[next(iter(optimalModel))][0]-optimalModel[next(iter(optimalModel))][1]):\n",
    "        optimalModel = {key: val}\n",
    "  return optimalModel\n",
    "\n",
    "optimalModel = parametersTuner(split = 9, leaf = 2, diff_threshold = 0.15)\n",
    "trainScore = next(iter(optimalModel.values()))[0]\n",
    "testScore = next(iter(optimalModel.values()))[1]\n",
    "\n",
    "optimalModel = next(iter(optimalModel.keys()))\n",
    "\n",
    "print('\\nTraining Data\\'s Accuracy Score: ', trainScore)\n",
    "print('Testing Data\\'s Accuracy Score: ', testScore)\n",
    "print(\"Selected Model: \", optimalModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25BL09lO1Nit"
   },
   "source": [
    "Highly Overfitted. But at least it is what it is and it is what was expected of this model. Now lets try Random Forest to improve the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bRRGFNCD1exM"
   },
   "source": [
    "##Trying Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "zrKatnHn0X-I",
    "outputId": "b3a79ae9-89a3-47b9-8613-7262312e93b9"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.3)\n",
    "randClassifier = RandomForestClassifier(n_estimators=15, criterion='entropy', max_depth=5)\n",
    "\n",
    "randClassifier.fit(X_train, y_train)\n",
    "\n",
    "predictedVals = randClassifier.predict(X_train)\n",
    "predictedTestVals = randClassifier.predict(X_test)\n",
    "\n",
    "print(\"Training Data's Confusion Matrix:\\n\", confusion_matrix(y_train, predictedVals))\n",
    "print(\"Testing Data\\'s Confusion Matrix:\\n\", confusion_matrix(y_test, predictedTestVals))\n",
    "\n",
    "print('\\nTraining Data\\'s Accuracy Score: ', accuracy_score(y_train, predictedVals))\n",
    "print('Testing Data\\'s Accuracy Score: ', accuracy_score(y_test, predictedTestVals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HRuc3Q1B-eIt"
   },
   "source": [
    "I don't know why but the accuracy is fluctuating everytime I train model.\n",
    "Oh, I know why, it's the same with previous models because of the random train-test split of the data. \n",
    "Lets graph the fluctuating prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 538
    },
    "id": "X_Y09UAf-rJq",
    "outputId": "ff88ae31-6223-435c-93db-adc02e98c295"
   },
   "outputs": [],
   "source": [
    "no_of_test = 100\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "for i in range(no_of_test):\n",
    "  X_train, X_test, y_train, y_test = train_test_split(x,y, test_size = 0.3)\n",
    "  randClassifier = RandomForestClassifier(n_estimators=15, criterion='entropy', max_depth=5)\n",
    "\n",
    "  randClassifier.fit(X_train, y_train)\n",
    "\n",
    "  train_accuracy.append(accuracy_score(y_train, randClassifier.predict(X_train)))\n",
    "  test_accuracy.append(accuracy_score(y_test, randClassifier.predict(X_test)))\n",
    "_, axs = plt.subplots(figsize=(20,8))\n",
    "plt.title(\"Accuracy Fluctuation Plot\")\n",
    "plt.xkcd()        #Comic style I find cool\n",
    "plt.plot(train_accuracy, color='red', label='Training Data\\'s prediction accuracy')\n",
    "plt.plot(test_accuracy, color='green', label='Testing Data\\'s prediction accuracy')\n",
    "plt.xlabel(\"No of tests done\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QnZz_yAMRZBG"
   },
   "source": [
    "Looking at the graph it seems like the fluctuating accuracies are sometimes soo good that it has perfectly optimized hyperparameters but sometimes the model is overfitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "id": "B9ellqe8R_B_",
    "outputId": "0cee20dc-b69c-49b5-b214-1c98a5aa1ad7"
   },
   "outputs": [],
   "source": [
    "print(\"Min training accuracy: \", min(train_accuracy))\n",
    "print(\"Max training Accuracy: \", max(train_accuracy))\n",
    "print(\"Min Testing Accuracy: \", min(test_accuracy))\n",
    "print(\"Max Testing accuracy: \", max(test_accuracy))\n",
    "\n",
    "max_training_deviation = 0\n",
    "min_training_deviation = math.inf\n",
    "for i in range(len(train_accuracy)):\n",
    "  if max_training_deviation < abs(train_accuracy[i]-test_accuracy[i]):\n",
    "    max_training_deviation = abs(train_accuracy[i]-test_accuracy[i])\n",
    "  if min_training_deviation > train_accuracy[i]-test_accuracy[i]:\n",
    "    min_training_deviation = train_accuracy[i]-test_accuracy[i]\n",
    "  \n",
    "\n",
    "print(\"\\nMax Accuracy Deviation: \", max_training_deviation)\n",
    "print(\"Min Accuracy Deviation: \", min_training_deviation)       #Negative sign indicates the testing data performed better with the model than training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try Bagging with different models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierList = [LogisticRegression(), DecisionTreeClassifier(), KNeighborsClassifier(), RandomForestClassifier()]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "def bestClassifier(givenModelList = [LogisticRegression()], deviationThreshold = 0.2):\n",
    "    '''\n",
    "        This function will select the best performing model among the given models with bagging algorithm.\n",
    "        Unfortunately it cannot select those by tuning their parameter weights, so, yeah, sorry.\n",
    "        Params: \n",
    "            givenModelList: List\n",
    "    '''\n",
    "    performanceRecord = {}   #Formet: {Model: (train accuracy, test accuracy, deviation)}\n",
    "    \n",
    "    #Test every model and record their performance\n",
    "    est=10\n",
    "    for model in givenModelList:\n",
    "        #Make a model\n",
    "        bagger = BaggingClassifier(base_estimator = model, n_estimators = est)\n",
    "\n",
    "        #Training\n",
    "        bagger.fit(X_train, y_train)\n",
    "\n",
    "        #Predicting\n",
    "        predictedVals = bagger.predict(X_train)\n",
    "        predictedTestVals = bagger.predict(X_test)\n",
    "\n",
    "        #Measuring test-train accuracy\n",
    "        train_accuracy = accuracy_score(y_train, predictedVals)\n",
    "        test_accuracy = accuracy_score(y_test, predictedTestVals)\n",
    "        \n",
    "        #Record the performance\n",
    "        performanceRecord[bagger] = (train_accuracy, test_accuracy, train_accuracy-test_accuracy)\n",
    "        \n",
    "    \n",
    "    sortedRecord = {k:v for k,v in sorted(performanceRecord.items(), key = lambda items: items[1][1], reverse=True)}\n",
    "    \n",
    "    #Select the model with best preformance\n",
    "    #Performance Better means with high test accuracy and less deviation\n",
    "    bestTillNow = {None: (0, 0, math.inf)}\n",
    "    \n",
    "    for k,v in sortedRecord.items():\n",
    "        if v[2] <= deviationThreshold:\n",
    "            bestTillNow = {k: v}\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                if next(iter(bestTillNow))[2] > v[2]:\n",
    "                    bestTillNow = {k: v}\n",
    "            except TypeError:\n",
    "                print(\"No model gave any result with that deviation threshold. It's too small.\")\n",
    "                return None, None\n",
    "    return bestTillNow, sortedRecord\n",
    "    \n",
    "bestClassifier, record = bestClassifier(givenModelList = classifierList, deviationThreshold = 0.1)\n",
    "bestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Best Bagging Classifier: ', next(iter(bestClassifier.keys())))\n",
    "accuracy = bestClassifier[next(iter(bestClassifier.keys()))]\n",
    "\n",
    "print('Training Accuracy: ', accuracy[0])\n",
    "print('Testing Accuracy: ', accuracy[1])\n",
    "print('Deviation: ', accuracy[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative deviation means that the training accuracy is lower than testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now time for some Boostins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gBooster = GradientBoostingClassifier(learning_rate = 0.01, n_estimators = 100, max_depth = 3)\n",
    "\n",
    "gBooster.fit(X_train, y_train)\n",
    "\n",
    "%timeit predictedVals = gBooster.predict(X_train)\n",
    "predictedTestVals = gBooster.predict(X_test)\n",
    "\n",
    "print(\"Training Data's Confusion Matrix:\\n\", confusion_matrix(y_train, predictedVals))\n",
    "print(\"Testing Data\\'s Confusion Matrix:\\n\", confusion_matrix(y_test, predictedTestVals))\n",
    "\n",
    "print('\\nTraining Data\\'s Accuracy Score: ', accuracy_score(y_train, predictedVals))\n",
    "print('Testing Data\\'s Accuracy Score: ', accuracy_score(y_test, predictedTestVals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "aBooster = AdaBoostClassifier(base_estimator = LogisticRegression(), learning_rate = 0.01, n_estimators = 100, algorithm = 'SAMME.R')\n",
    "\n",
    "aBooster.fit(X_train, y_train)\n",
    "\n",
    "predictedVals = aBooster.predict(X_train)\n",
    "predictedTestVals = aBooster.predict(X_test)\n",
    "\n",
    "print(\"Training Data's Confusion Matrix:\\n\", confusion_matrix(y_train, predictedVals))\n",
    "print(\"Testing Data\\'s Confusion Matrix:\\n\", confusion_matrix(y_test, predictedTestVals))\n",
    "\n",
    "print('\\nTraining Data\\'s Accuracy Score: ', accuracy_score(y_train, predictedVals))\n",
    "print('Testing Data\\'s Accuracy Score: ', accuracy_score(y_test, predictedTestVals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_tests = 100\n",
    "trAccuracyHistory = []\n",
    "teAccuracyHistory = []\n",
    "\n",
    "for i in range(no_of_tests):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "    aBooster = AdaBoostClassifier(base_estimator = LogisticRegression(), learning_rate = 0.01, n_estimators = 100, algorithm = 'SAMME.R')\n",
    "\n",
    "    aBooster.fit(X_train, y_train)\n",
    "\n",
    "    predictedVals = aBooster.predict(X_train)\n",
    "    predictedTestVals = aBooster.predict(X_test)\n",
    "    \n",
    "    trAccuracyHistory.append(accuracy_score(y_train, predictedVals))\n",
    "    teAccuracyHistory.append(accuracy_score(y_test, predictedTestVals))\n",
    "\n",
    "plt.title(\"Accuracy Fluctuation Plot\")\n",
    "plt.xkcd()        #Comic style I find cool\n",
    "plt.plot(trAccuracyHistory, color='red', label='Training Data\\'s prediction accuracy')\n",
    "plt.plot(teAccuracyHistory, color='green', label='Testing Data\\'s prediction accuracy')\n",
    "plt.xlabel(\"No of tests done\")\n",
    "plt.ylabel(\"Accuracy Score\")\n",
    "plt.grid()\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HeartDisease.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
